{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "NLP day 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQP44ykL9aqT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Word2Vec Model\n",
        "- Word2Vec Google's Pretrained Model\n",
        "- Contains vector representations of 50 billion words\n",
        "\n",
        "- Words which are similar in context have similar vectors\n",
        "- Distance/Similarity between two words can be measured using Cosine Distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FIJxjZF9aqU",
        "colab_type": "text"
      },
      "source": [
        "### Applications\n",
        "- Text Similarity\n",
        "- Language Translation\n",
        "- Finding Odd Words\n",
        "- Word Analogies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1uajVQu9aqU",
        "colab_type": "text"
      },
      "source": [
        "### Word Embeddings\n",
        "- Word embeddings are numerical representation of words, in the form of vectors.\n",
        "\n",
        "- Word2Vec Model represents each word as 300 Dimensional Vector\n",
        "\n",
        "- In this tutorial we are going to see how to use pre-trained word2vec model.\n",
        "- Model size is around 1.5 GB\n",
        "- We will work using Gensim, which is popular NLP Package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMcMbYNb9aqV",
        "colab_type": "text"
      },
      "source": [
        "Gensim's Word2Vec Model provides optimum implementation of \n",
        "\n",
        "1) **CBOW** Model \n",
        "\n",
        "2) **SkipGram Model**\n",
        "\n",
        "\n",
        "Paper 1 [Efficient Estimation of Word Representations in\n",
        "Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "\n",
        "\n",
        "Paper 2 [Distributed Representations of Words and Phrases and their Compositionality\n",
        "](https://arxiv.org/abs/1310.4546)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PTatJHq9aqV",
        "colab_type": "text"
      },
      "source": [
        "### Word2Vec using Gensim\n",
        "`Link https://radimrehurek.com/gensim/models/word2vec.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYb6gmPcTAG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3555c20d-c234-4b39-dcdd-67344bf8e389"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-17 06:48:27--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.128.229\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.128.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  92.5MB/s    in 21s     \n",
            "\n",
            "2020-07-17 06:48:47 (76.0 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB3CGq2R9aqW",
        "colab_type": "text"
      },
      "source": [
        "# CODE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hjsK91B9aqW",
        "colab_type": "text"
      },
      "source": [
        "##### Load Word2Vec Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pw657wN9aqX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**KeyedVectors** - This object essentially contains the mapping between words and embeddings. After training, it can be used directly to query those embeddings in various ways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpDsONQn9aqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors , Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKi3ygxU9aqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cdb1df16-7139-4fe4-c59d-220885e30a25"
      },
      "source": [
        "word_vector = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin.gz', binary= True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZAGGCpp9aqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfdb5e00-1391-46e3-92b0-d0d8060dce25"
      },
      "source": [
        "type(word_vector)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG0JWNVwVzSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baa4bd0f-b7cb-45b0-ad3b-c9de7fdadc7a"
      },
      "source": [
        " Apple = word_vector['Apple']\n",
        " Apple"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.74804688e-01,  3.00292969e-02, -2.16796875e-01,  1.56250000e-01,\n",
              "       -3.57421875e-01, -6.05468750e-02,  1.36718750e-01,  9.57031250e-02,\n",
              "        3.17382812e-03, -4.29687500e-02, -3.30078125e-01,  2.57812500e-01,\n",
              "        2.51953125e-01, -2.77343750e-01, -6.98242188e-02, -2.95410156e-02,\n",
              "        3.22265625e-01, -7.76367188e-02, -3.06396484e-02, -1.67968750e-01,\n",
              "       -5.76171875e-02,  3.05175781e-02,  5.52368164e-03, -1.26953125e-01,\n",
              "       -1.44042969e-02,  1.75781250e-01,  9.47265625e-02,  3.16406250e-01,\n",
              "       -7.81250000e-03, -3.40270996e-03,  3.63769531e-02,  1.11816406e-01,\n",
              "       -1.24023438e-01,  1.29882812e-01, -3.22265625e-02, -1.60156250e-01,\n",
              "        7.56835938e-02,  6.73828125e-02,  4.08203125e-01,  2.23632812e-01,\n",
              "        1.60156250e-01,  3.63769531e-02, -1.64062500e-01, -3.51562500e-01,\n",
              "        4.49218750e-02,  6.34765625e-02, -1.15234375e-01,  3.12500000e-01,\n",
              "       -2.80761719e-02, -9.22851562e-02,  5.98144531e-02,  1.57470703e-02,\n",
              "       -1.15234375e-01,  2.18750000e-01, -5.78613281e-02,  2.07031250e-01,\n",
              "       -1.03515625e-01, -2.07031250e-01, -7.08007812e-02, -7.47070312e-02,\n",
              "        1.35742188e-01,  1.80664062e-01, -2.50000000e-01, -3.27148438e-02,\n",
              "       -9.76562500e-02, -7.81250000e-02,  7.32421875e-03,  2.47070312e-01,\n",
              "       -1.75781250e-01,  1.21459961e-02, -2.49023438e-01, -5.61523438e-02,\n",
              "        4.10156250e-02, -1.59179688e-01, -3.34472656e-02, -7.29370117e-03,\n",
              "       -1.11328125e-01, -2.03125000e-01,  1.00585938e-01, -1.26953125e-01,\n",
              "       -6.93359375e-02, -1.02539062e-02, -1.81640625e-01, -1.54296875e-01,\n",
              "       -7.91015625e-02, -4.08203125e-01,  3.22265625e-01,  2.91015625e-01,\n",
              "       -2.69531250e-01, -1.61132812e-01, -2.92968750e-01,  1.17675781e-01,\n",
              "       -1.64062500e-01, -1.21582031e-01,  1.26953125e-01, -3.14453125e-01,\n",
              "       -2.66113281e-02,  8.10546875e-02,  1.18652344e-01,  8.30078125e-02,\n",
              "        3.07617188e-02, -7.71484375e-02, -2.08984375e-01,  1.27929688e-01,\n",
              "        5.88378906e-02, -1.55273438e-01, -6.98242188e-02,  1.03027344e-01,\n",
              "        4.68750000e-02, -4.57031250e-01, -3.61328125e-01, -4.99725342e-04,\n",
              "        2.37304688e-01, -4.79125977e-03,  1.39648438e-01, -5.78613281e-02,\n",
              "       -2.39257812e-01, -4.35546875e-01, -8.44726562e-02,  3.44238281e-02,\n",
              "       -4.93164062e-02, -1.54296875e-01, -3.32031250e-01, -2.16796875e-01,\n",
              "        1.65039062e-01, -1.12792969e-01, -1.45507812e-01,  1.60156250e-01,\n",
              "       -3.59375000e-01,  8.10546875e-02, -1.20605469e-01, -4.46777344e-02,\n",
              "       -2.25585938e-01, -5.66406250e-02, -7.91015625e-02,  1.11694336e-02,\n",
              "        2.20947266e-02, -2.28271484e-02, -5.56640625e-02, -1.66992188e-01,\n",
              "        1.75781250e-02, -1.39648438e-01, -2.51953125e-01, -3.59375000e-01,\n",
              "        2.20703125e-01, -5.34667969e-02,  3.22265625e-01, -1.91406250e-01,\n",
              "       -5.74218750e-01, -1.58203125e-01, -5.85937500e-02, -2.17773438e-01,\n",
              "       -1.30859375e-01, -4.61425781e-02, -2.53906250e-01,  3.61328125e-02,\n",
              "       -1.58203125e-01, -1.39648438e-01, -4.71191406e-02,  2.44140625e-01,\n",
              "       -3.30078125e-01, -1.82617188e-01, -8.88671875e-02, -1.11694336e-02,\n",
              "       -9.71679688e-02, -1.52343750e-01,  3.20312500e-01,  2.14843750e-02,\n",
              "       -5.03540039e-03,  6.39648438e-02, -9.37500000e-02, -1.69921875e-01,\n",
              "       -7.91015625e-02, -1.50390625e-01, -1.73828125e-01,  1.05468750e-01,\n",
              "        2.55859375e-01, -9.61914062e-02, -2.52685547e-02, -1.06933594e-01,\n",
              "       -2.41210938e-01, -8.20312500e-02,  5.88378906e-02, -2.75390625e-01,\n",
              "        2.21679688e-01,  6.12792969e-02,  1.86767578e-02,  2.91015625e-01,\n",
              "       -8.64257812e-02, -6.93359375e-02,  1.35498047e-02,  1.76757812e-01,\n",
              "       -5.07812500e-02, -2.08984375e-01, -1.37695312e-01,  1.46484375e-01,\n",
              "       -3.10546875e-01, -2.28515625e-01, -1.54296875e-01,  3.73535156e-02,\n",
              "        9.46044922e-03, -2.43164062e-01,  1.40625000e-01,  3.02734375e-01,\n",
              "       -2.31933594e-03,  1.67968750e-01,  1.33789062e-01, -1.10839844e-01,\n",
              "       -2.50000000e-01,  2.42919922e-02,  4.93164062e-02,  1.84570312e-01,\n",
              "       -1.67236328e-02,  9.27734375e-02, -1.72851562e-01, -4.00390625e-02,\n",
              "        6.68945312e-02,  1.25000000e-01, -2.12890625e-01, -3.78906250e-01,\n",
              "       -3.65234375e-01,  3.67187500e-01,  9.03320312e-02,  2.31445312e-01,\n",
              "       -1.35742188e-01,  1.17675781e-01, -4.68750000e-02,  2.80761719e-02,\n",
              "        1.63085938e-01,  9.08203125e-02, -4.17968750e-01, -1.88476562e-01,\n",
              "       -2.29492188e-01, -3.69140625e-01,  1.41601562e-01, -1.41601562e-02,\n",
              "        1.48437500e-01, -1.83593750e-01,  1.08886719e-01,  8.00781250e-02,\n",
              "        2.38281250e-01, -1.51977539e-02, -1.61132812e-02, -4.41406250e-01,\n",
              "        4.41894531e-02, -1.80664062e-01, -1.89453125e-01, -3.44848633e-03,\n",
              "       -9.96093750e-02, -1.35742188e-01, -4.49218750e-01,  2.10937500e-01,\n",
              "        3.34472656e-02,  1.66015625e-01,  1.55273438e-01,  2.00195312e-01,\n",
              "        1.79687500e-01,  5.37109375e-02, -1.93359375e-01,  3.10546875e-01,\n",
              "        2.94921875e-01,  2.70996094e-02,  2.51464844e-02,  2.50000000e-01,\n",
              "       -5.78613281e-02,  2.08007812e-01, -3.51562500e-01, -1.26953125e-01,\n",
              "        1.02050781e-01, -2.87109375e-01,  1.17187500e-01,  1.41601562e-01,\n",
              "        7.22656250e-02, -3.36914062e-02,  2.13867188e-01, -3.54003906e-02,\n",
              "        3.12500000e-01, -1.07421875e-01, -1.29882812e-01,  2.66113281e-02,\n",
              "       -1.25976562e-01,  3.26171875e-01,  2.96630859e-02,  3.02734375e-01,\n",
              "        1.20117188e-01, -1.16210938e-01,  5.49316406e-02,  1.15356445e-02,\n",
              "        6.25000000e-02,  3.02734375e-01,  1.34765625e-01, -9.22851562e-02,\n",
              "        3.36914062e-02, -1.59179688e-01,  3.45703125e-01, -6.73828125e-02,\n",
              "       -2.44140625e-01, -1.79443359e-02, -1.06445312e-01,  2.57812500e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbuWp3H39aqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5479e8c7-01fc-4b05-cf8d-96296072357f"
      },
      "source": [
        "Apple.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ov1TGEb9aqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mango = word_vector['mango']\n",
        "apple = word_vector['apple']\n",
        "banana = word_vector['banana']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "998UX2XgDJNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74276b8c-1100-493a-c64f-0da9698d9510"
      },
      "source": [
        "cosine_similarity([Apple], [mango])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11593594]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk79LyjHDJJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35d6b0f7-9c0e-4a72-bbc9-9f1f903708e5"
      },
      "source": [
        "cosine_similarity([apple], [mango])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57518554]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPJ5kRUjDJGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0a56068-35a9-4ae1-e29e-7b1abdee4a45"
      },
      "source": [
        "cosine_similarity([banana], [mango])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63652116]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp5DlSg0DJC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "349ea2ff-544c-4898-a22f-f6e3ccf5faaf"
      },
      "source": [
        "Google = word_vector['Google']\n",
        "cosine_similarity([Apple], [Google])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.56835705]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLBMOoSX9aqo",
        "colab_type": "text"
      },
      "source": [
        "## 1. Find the Odd One Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skH-2A-9aqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def odd_one_out(words):\n",
        "    \"\"\"Accepts a list of words and returns the odd word\"\"\"\n",
        "    # print(words)\n",
        "    # all_word_vec = []\n",
        "    # for i in words:\n",
        "    #     all_word_vec.append(word_vector[i])\n",
        "    all_word_vec = [word_vector[i] for i in words]\n",
        "    # print(len(all_word_vec), all_word_vec[0].shape)\n",
        "\n",
        "    avg_vec = np.mean(all_word_vec, axis = 0)\n",
        "    # print(avg_vec.shape)\n",
        "\n",
        "    odd_word = None\n",
        "    max_sim = 2\n",
        "    for word in words:\n",
        "        temp_sim = cosine_similarity([avg_vec], [word_vector[word]])\n",
        "        print(f\"avg_vec and {word} ---> {temp_sim}\")\n",
        "\n",
        "        if temp_sim < max_sim:\n",
        "            max_sim = temp_sim\n",
        "            odd_word = word\n",
        "\n",
        "    return odd_word"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW1nRcM8q9Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = [10,2,34,6,8,2,4]\n",
        "# # min = 100000000\n",
        "# max = -100000000\n",
        "# for i in a:\n",
        "#     if i > max:\n",
        "#         max= i\n",
        "# print(max)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ02KewtXl6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85c98813-f830-4563-e9e0-5e1ad6a5c127"
      },
      "source": [
        "odd_one_out(input_1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_vec and apple ---> [[0.7806554]]\n",
            "avg_vec and mango ---> [[0.7606032]]\n",
            "avg_vec and juice ---> [[0.7106042]]\n",
            "avg_vec and party ---> [[0.357093]]\n",
            "avg_vec and orange ---> [[0.649024]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'party'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvQZBrLt9aqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_1 = [\"apple\",\"mango\",\"juice\",\"party\",\"orange\"] \n",
        "input_2 = [\"music\",\"dance\",\"sleep\",\"dancer\",\"food\"]        \n",
        "input_3  = [\"match\",\"player\",\"football\",\"cricket\",\"dancer\"]\n",
        "input_4 = [\"india\",\"paris\",\"russia\",\"france\",\"germany\"]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv3z-IY69aqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "61217d22-3fb5-4b34-dc5d-2703305b0744"
      },
      "source": [
        "odd_word = odd_one_out(input_1)\n",
        "print(f\"odd word in the given list is --> {odd_word}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_vec and apple ---> [[0.7806554]]\n",
            "avg_vec and mango ---> [[0.7606032]]\n",
            "avg_vec and juice ---> [[0.7106042]]\n",
            "avg_vec and party ---> [[0.357093]]\n",
            "avg_vec and orange ---> [[0.649024]]\n",
            "odd word in the given list is --> party\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isubp-Fu9aqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "6dce6714-7c87-4523-c64f-62ad98abd298"
      },
      "source": [
        "odd_word = odd_one_out(input_2)\n",
        "print(f\"odd word in the given list is --> {odd_word}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_vec and music ---> [[0.66403615]]\n",
            "avg_vec and dance ---> [[0.80607384]]\n",
            "avg_vec and sleep ---> [[0.5149707]]\n",
            "avg_vec and dancer ---> [[0.7154054]]\n",
            "avg_vec and food ---> [[0.51771235]]\n",
            "odd word in the given list is --> sleep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA6tJ_Et9aqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "92d7c698-6c65-4f50-f0f7-672a660deb86"
      },
      "source": [
        "odd_word = odd_one_out(input_3)\n",
        "print(f\"odd word in the given list is --> {odd_word}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_vec and match ---> [[0.5837205]]\n",
            "avg_vec and player ---> [[0.6805351]]\n",
            "avg_vec and football ---> [[0.72256005]]\n",
            "avg_vec and cricket ---> [[0.69646657]]\n",
            "avg_vec and dancer ---> [[0.52681357]]\n",
            "odd word in the given list is --> dancer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng9yzgiv9aq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0cc2b351-197a-4e33-c3f0-2ef4d84f2e54"
      },
      "source": [
        "odd_word = odd_one_out(input_4)\n",
        "print(f\"odd word in the given list is --> {odd_word}\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg_vec and india ---> [[0.80707854]]\n",
            "avg_vec and paris ---> [[0.74804693]]\n",
            "avg_vec and russia ---> [[0.79275256]]\n",
            "avg_vec and france ---> [[0.8136487]]\n",
            "avg_vec and germany ---> [[0.841681]]\n",
            "odd word in the given list is --> paris\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFkA0FIk9aq3",
        "colab_type": "text"
      },
      "source": [
        "### 2. Word Analogies Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnAE72io9aq3",
        "colab_type": "text"
      },
      "source": [
        "In the word analogy task, we complete the sentence \"a is to b as c is to __\". An example is 'man is to woman as king is to queen' . In detail, we are trying to find a word d, such that the associated word vectors `ea,eb,ec,ed` are related in the following manner: `eb−ea≈ed−ec`. We will measure the similarity between `eb−ea` and `ed−ec` using cosine similarity. \n",
        "\n",
        "![Word2Vec](http://jalammar.github.io/images/word2vec/word2vec.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv4XJS3aaqUB",
        "colab_type": "text"
      },
      "source": [
        "**man -> woman ::     prince -> princess**\n",
        "**italy -> italian ::     spain -> spanish**\n",
        "**india -> delhi ::     japan -> tokyo**\n",
        "**man -> woman ::     boy -> girl**\n",
        "**small -> smaller ::     large -> larger**\n",
        "\n",
        "## Try it out\n",
        "**man -> coder :: woman -> ______?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H45CIfH9aIGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vector.vocab.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9vpGtyGaIDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_word(a, b, c, model) :\n",
        "    \"\"\"Accepts a triad of words, a,b,c and returns d such that a is to b : c is to d\"\"\"\n",
        "    wv_a, wv_b, wv_c = model[a], model[b], model[c]\n",
        "    min_sim = -10\n",
        "    pred = None\n",
        "    words = model.wv.vocab.keys()\n",
        "\n",
        "    for w in words:\n",
        "        if w in [a, b, c]:\n",
        "            continue\n",
        "        \n",
        "        wv_w = model[w]\n",
        "\n",
        "        temp_sim = cosine_similarity([wv_b - wv_a], [wv_w - wv_c])\n",
        "\n",
        "        if temp_sim > min_sim:\n",
        "            min_sim = temp_sim\n",
        "            pred = w\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0XEyIyYaIBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "11ce33f8-6be2-46ab-9b0d-7e83c5538c87"
      },
      "source": [
        "a, b, c = \"man\", \"woman\", \"prince\"\n",
        "predict_word(a, b, c, word_vector)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'princess'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhGIF7roaH_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX5kILTZ9arG",
        "colab_type": "text"
      },
      "source": [
        "## 3. Training Your Own Word2Vec Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW5OYHuj9arH",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec model can learn embeddings from any text corpus!\n",
        "- Continuous Bag of Words Model **(CBOW)**\n",
        "- Skip Gram Model\n",
        "\n",
        "`Algorithm looks at window of target word(Y) to provide context word(X), the model is trained on (X,Y) pairs in a superwised manner.` The algorithm was developed by Tomas Mikolov."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGQ_yeiw9arH",
        "colab_type": "text"
      },
      "source": [
        "#### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzUQje3T9arH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- Each sentence must be tokenized, into a list of words.\n",
        "\n",
        "- The sentences can be text loaded into memory once,\n",
        "or we can build a data pipeline which iteratively feeds data to the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCuv9q8C9arI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "00e81806-78df-4e0e-d796-3ffac088295d"
      },
      "source": [
        "#libs\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcFpaGayhVbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "023abd3f-1cc9-4779-d343-b341c4b8b65f"
      },
      "source": [
        "print(stopwords.words('english'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB3uV7lb9arM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Read the file \n",
        "def readFile(file): \n",
        "    f = open(file, 'r')\n",
        "    text = f.read()\n",
        "    # print(text)\n",
        "\n",
        "    sent = nltk.sent_tokenize(text)\n",
        "\n",
        "    data = []\n",
        "    for s in sent:\n",
        "        words = nltk.word_tokenize(s)\n",
        "        words = [w.lower() for w in words if w.lower() not in stopwords.words('english') and len(w) > 2]\n",
        "        data.append(words)\n",
        "    return data"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRPhhjWxuwRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e70dbfa4-306d-4621-e777-0f31ca2ed3d4"
      },
      "source": [
        "a = \"This year was the year of big fat 2019 lavish 2020 and 99542654862656 extravagant weddings.\"\n",
        "# print(a)\n",
        "b = nltk.sent_tokenize(a)\n",
        "# print(type(b))\n",
        "# b\n",
        "\n",
        "for i in b:\n",
        "    # print(i)\n",
        "    i = re.sub('[^a-zA-Z]', \" \", i)\n",
        "    i = re.sub('[ \\t\\n]+', ' ', i)\n",
        "    print(i)\n",
        "    w = nltk.word_tokenize(i)\n",
        "    w = [j.lower() for j in w if j.lower() not in stopwords.words('english') and len(j) > 2]\n",
        "    # temp = []\n",
        "    # for j in w:\n",
        "    #     if j.lower() not in stopwords.words('english') and len(j) > 2:\n",
        "    #         temp.append(j.lower())\n",
        "    # w = temp\n",
        "    print(w)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This year was the year of big fat lavish and extravagant weddings \n",
            "['year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgItTvUd9arN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = '/content/bollywood_news.txt'\n",
        "text = readFile(file)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Se5cNDyQwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a4fff314-e481-4b57-bc71-b8d301aa38b4"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['deepveer', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'ranveer', 'wedding', 'style', 'file'], ['ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'year', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['nothing', 'beats', 'man', 'wedding', 'year', 'award', 'social', 'media'], ['wedding', 'season', 'year', 'kicked', 'deepika', 'padukone', 'ranveer', 'singh', 'flew', 'lake', 'como', 'tie', 'knot', 'two', 'days', 'november'], ['several', 'lavish', 'wedding', 'reception', 'parties', 'bengaluru', 'mumbai'], ['even', 'deepika', 'ranveer', 'wedding', 'reception', 'parties', 'continued', 'priyanka', 'chopra', 'tied', 'knot', 'american', 'singer', 'nick', 'jonas', 'jodhpur', 'december', 'yet', 'another', 'grand', 'wedding', 'spread', 'week'], ['priyanka', 'nick', 'hosted', 'reception', 'parties', 'delhi', 'december', 'mumbai', 'december'], ['couple', 'yet', 'host', 'another', 'reception', 'party', 'los', 'angeles'], ['time', 'priyanka', 'chopra', 'nick', 'jonas', 'could', 'move', 'wedding', 'reception', 'parties', 'mukesh', 'nita', 'ambani', 'daughter', 'isha', 'ambani', 'ajay', 'swati', 'piramal', 'son', 'anand', 'piramal', 'pre-wedding', 'festivities', 'took', 'udaipur'], ['december'], ['two-day', 'events', 'udaipur', 'culminated', 'performance', 'american', 'pop', 'sensation', 'beyonce'], ['soon', 'december', 'isha', 'anand', 'tied', 'knot', 'antilia', 'mumbai', 'event', 'followed', 'three', 'reception', 'parties'], ['three', 'high-profile', 'weddings', 'several', 'stars', 'tied', 'knot'], ['star', 'kapil', 'sharma', 'married', 'ginni', 'chatrath', 'ace', 'badminton', 'player', 'saina', 'nehwal', 'parupalli', 'kashyap', 'tied', 'knot', 'cricketer', 'sanju', 'samson', 'married', 'college', 'sweetheart', 'charulatha'], ['wedding', 'rizwan', 'pehelwan', 'much', 'like', 'many', 'couples', 'close-knit', 'weddings', 'year', 'probably', 'took', 'wedding', 'cake'], ['deepika', 'ranveer', 'known', 'airport', 'twinning', 'appearances', 'surprise', 'see', 'twin', 'white', 'left', 'destination', 'wedding', 'italy'], ['deepika', 'ranveer', 'two', 'wedding', 'ceremonies', 'everyone', 'knows', 'one', 'sindhi', 'konkani'], ['sindhi', 'wedding', 'seen', 'wearing', 'custom-made', 'sabyasachi', 'ensembles', 'traditional', 'gorgeous', 'silk', 'saree', 'deepika', 'ranveer', 'white', 'silk', 'kurta', 'gorgeous', 'backdrop', 'lake', 'como', 'italy', 'perfect'], ['couple', 'seen', 'sabyasachi', 'yet', 'made', 'way', 'back', 'bay', 'celebrating', 'union', 'italy'], ['love', 'two', 'wore', 'neutral', 'colours', 'added', 'pop', 'dupatta', 'waistcoat'], ['celebrations', 'began', 'bangalore', 'reception', 'deepika', 'seen', 'stunning', 'sabyasachi', 'saree', 'ranveer', 'sherwani'], ['celebrations', 'began', 'bangalore', 'reception', 'deepika', 'dressed', 'stunning', 'sabyasachi', 'saree', 'ranveer', 'sherwani'], ['ranveer', 'handcrafted', 'anti-fit', 'long', 'silk', 'jacket', 'manish', 'arora', 'signature', 'heart', 'motif', 'complete', 'leopard', 'head', 'attached', 'right', 'shoulder'], ['deepika', 'flowed', 'vibe', 'fully', 'floral', 'sabyasachi', 'saree', 'wowed'], ['deepika', 'wearing', 'gorgeous', 'chikankari', 'creation', 'abu', 'jani', 'sandeep', 'khosla', 'ranveer', 'wore', 'custom-made', 'sherwani'], ['newlywed', 'power', 'couple', 'priyanka', 'chopra', 'nick', 'jonas', 'cloud', 'nine', 'fairytale', 'wedding', 'three', 'back-to-back', 'wedding', 'receptions'], ['couple', 'tied', 'knot', 'umaid', 'bhawan', 'palace', 'jodhpur', 'december', 'private', 'wedding', 'affair'], ['since', 'world', \"n't\", 'get', 'pictures', 'bollywood-hollywood', 'couple'], ['thought', 'got', 'wedding', 'galore', 'eyes', 'felt', 'beautiful', 'pictures', 'couple'], ['priyanka', 'nick', 'looking', 'extremely', 'gorgeous', 'pictures'], ['man', 'moment', 'nick', 'jonas', 'perfectly', 'complements', 'lady', 'love', 'priyanka', 'corners'], ['priyanka', 'smile', 'make', 'everybody', 'fall'], ['four', 'days', 'wedding', 'festivities', 'topped', 'three', 'receptions', 'party', 'still', 'newlyweds', 'priyanka', 'chopra', 'nick', 'jonas'], ['couple', 'tied', 'knot', 'december', 'elaborate', 'ceremonies', 'reportedly', 'host', 'big', 'bash', 'los', 'angeles', 'hollywood', 'friends'], ['according', 'reports', 'rounds', 'couple', 'allegedly', 'host', 'black-tie', 'event', 'priyanka', 'close', 'friends', 'like', 'kerry', 'washington', 'dwayne', 'johnson', 'ellen', 'degeneres', 'among', 'co-stars', 'many', 'films', 'show', 'quantico'], ['reports', 'even', 'suggest', 'pregnant', 'duchess', 'sussex-', 'meghan', 'markle', 'also', 'received', 'invite'], ['meanwhile', 'nick', 'friends', 'music', 'industry', 'also', 'expected', 'join', 'festivities'], ['priyanka', 'chopra', 'nick', 'jonas', 'got', 'married', 'month', 'jodhpur', 'umaid', 'bhawan', 'palace'], ['less', 'fairytale', 'wedding'], ['dating', 'months', 'duo', 'decided', 'take', 'relationship', 'next', 'level'], ['got', 'man', 'looking'], ['nick', 'took', 'instagram', 'story', 'express', 'amazing', 'year', 'posting', 'collage', 'pictures', 'best', 'moments', 'bollywood', 'diva', 'took', 'place', 'year'], ['adorable', 'would', 'understatement'], ['nick', 'jonas', 'priyanka', 'chopra', 'dominated', 'social', 'media', 'since', 'time', 'announced', 'relationship', 'since', 'giving', 'major', 'couple', 'goals'], ['couple', 'tied', 'knot', 'umaid', 'bhawan', 'palace', 'jodhpur', 'per', 'hindu', 'christian', 'traditions', 'raised', 'bar', 'next', 'level'], ['thought', 'seen', 'wedding', 'another', 'adorable', 'picture', 'nickyanka', 'fairytale', 'wedding', 'celebrations', 'wherein', 'see', 'nick', 'escorting', 'ladylove'], ['hours', 'ago', 'peecee', 'taken', 'instagram', 'share', 'picture', 'hubby', 'wherein', 'could', 'seen', 'posing', 'bollywood', 'style', 'nick', 'holding', 'wife', 'arms'], ['priyanka', 'chopra', 'nick', 'jonas', 'become', 'one', 'loved', 'couples', 'bollywood'], ['two', 'always', 'look', 'simply', 'adorable', 'together', 'latest', 'picture', 'couple', 'proof'], ['got', 'hands', 'picture', 'priyanka', 'nick', 'captured', 'candidly', 'flight', 'journey', 'together'], ['picture', 'peecee', 'seen', 'fidgeting', 'something', 'nick', 'looks'], ['dim', 'light', 'background', 'light', 'face', 'window', 'give', 'picture', 'vintage', 'look'], ['priyanka', 'nick', 'took', 'nuptial', 'vows', 'umaid', 'bhavan', 'palace', 'udaipur', 'presence', 'families', 'friends'], ['two', 'honoured', 'cultures', 'wedding'], ['lavish', 'wedding', 'also', 'threw', 'grand', 'wedding', 'reception', 'delhi', 'graced', 'narendra', 'modi'], ['bollywood', 'diva', 'priyanka', 'chopra', 'american', 'pop', 'singer', 'nick', 'jonas', 'got', 'married', 'jodhpur', 'umaid', 'bhawan', 'palace', 'december'], ['couple', 'sharing', 'pictures', 'socials', 'media', 'giving', 'major', 'couple', 'goals'], ['recently', 'took', 'instagram', 'post', 'picture', 'nick', 'photo', 'shoot', 'took', 'place', 'wedding'], ['captioned', 'image', 'look', 'wonder', 'lies', 'ahead..', 'filled', 'joy..', 'mesmerising', 'fans', 'followers', 'love', 'story', 'lavish', 'wedding', 'bollywood', 'actress', 'priyanka', 'chopra', 'nick', 'jonas', 'yesterday', 'flew', 'back', 'america'], ['recently', 'shared', 'picture', 'adorable', 'nieces', 'cute', 'words'], ['singer', 'actor', 'took', 'instagram', 'handle', 'share', 'picture', 'see', 'working', 'magic', 'keys', 'piano', 'along', 'two', 'beautiful', 'nieces', 'seem', 'teaching', 'play'], ['captioned', 'picture', 'beautiful', 'nieces', 'teaching', 'everything', 'know', 'keys'], ['couple', 'got', 'hitched', 'umaid', 'bhavan', 'palace', 'jodhpur', 'always', 'open', 'idea', 'kids', 'starting', 'family'], ['speaking', 'nick', 'reportedly', 'said', 'definitely', 'wants', 'father', 'someday'], ['even', 'rumours', 'nick', 'jonas', 'priyanka', 'chopra', 'relationship', 'two', 'gave', 'major', 'couple', 'goals'], ['lovebirds', 'actually', 'called', 'official', 'tying', 'knot', 'bar', 'set', 'higher'], ['giving', 'serious', 'couple', 'goals', 'nick', 'jonas', 'taken', 'social', 'media', 'handle', 'share', 'adorable', 'picture', 'priyanka', 'chopra', 'christian', 'wedding'], ['picture', 'features', 'newlyweds', 'cutting', 'huge', 'scrumptious', 'look', 'wedding', 'cake'], ['captioned', 'picture', 'one', 'week', 'ago', 'today'], ['beautiful', 'couple', 'recently', 'seen', 'pairing', 'ethnic', 'ensemble', 'isha', 'ambani', 'anand', 'piramal', 'pre-wedding', 'festivity', 'cricketer', 'virat', 'kohli', 'wife', 'actor', 'anushka', 'sharma', 'spending', 'new', 'year', 'holiday', 'sydney', 'australia', 'shared', 'new', 'photos', 'give', 'glimpse', 'fans', 'celebrations', 'like'], ['standing', 'street', 'looked', 'ready', 'party', 'couple', 'looks', 'directly', 'camera'], ['anushka', 'shared', 'another', 'photos', 'seen', 'posing', 'husband'], ['busy', 'year', 'virat', 'anushka'], ['actor', 'three', 'releases', 'year', 'production', 'pari', 'sui', 'dhaaga', 'co-starring', 'varun', 'dhawan', 'zero', 'played', 'scientist', 'cerebral', 'palsy', 'virat', 'maintained', 'pole', 'position', 'year-end', 'icc', 'test', 'player', 'rankings'], ['india', 'also', 'taken', '2-1', 'lead', 'four-match', 'series', 'australia', 'ongoing', 'test', 'series'], ['rajput/instagram', 'kareena', 'kapoor', 'khan', 'anushka', 'sharma', 'sonam', 'kapoor', 'arjun', 'kapoor', 'rajkummar', 'rao', 'among', 'others', 'b-town', 'celebrities', 'spent', 'new', 'year', 'loved', 'ones'], ['alia', 'bhatt', 'joined', 'ranbir', 'kapoor', 'family', 'celebrate', 'new', 'year'], ['ranbir', 'sister', 'riddhima', 'kapoor', 'sahni', 'shared', 'sneak', 'peek', 'celebrations'], ['also', 'saw', 'mira', 'rajput', 'posting', 'perfect', 'family', 'portrait', 'instagram', 'wishing', 'followers', 'shahid', 'kapoor', 'fans', 'happy', 'new', 'year'], ['neetu', 'kapoor', 'shared', 'photo', 'instagram', 'hoped', '2019', 'step', 'closer', 'times', 'cancer', 'zodiac', 'sign', 'happy', '2019', 'resolutions', 'wishes', 'year'], ['less', 'pollution', 'traffic'], ['hope', 'future', 'cancer', 'zodiac', 'sign'], ['hatred', 'less', 'poverty', 'loads', 'love', 'togetherness', 'happiness', 'imp'], ['good', 'health', 'anushka', 'sharma', 'sydney', 'virat', 'kohli', 'wrote', 'hope', 'wake', 'new', 'year', 'filled', 'hope', 'peace', 'compassion', 'may', 'strive', 'kinder', 'one', 'another', 'illuminate', 'light', 'beauty', 'resides', 'within', 'happy', 'new', 'year', 'another', 'photo', 'alia', 'looks', 'extremely', 'happy', 'company', 'ranbir', 'family'], ['source', 'riddhima', 'kapoor', 'sahni/', 'instagram', 'weird', 'news', '2019', 'dosa', 'named', 'deepika', 'padukone', 'texas'], ['actor', 'retweeted', 'fan', 'post', 'dosa', 'saying', 'great', 'way', 'begin', 'year', '...', 'happy', 'new', 'year', 'dosa', 'comes', 'potato', 'mix', 'topped', 'fiery', 'red', 'ghost', 'chillis'], ['deepika', 'padukone', 'deepikapadukone', 'great', 'way', 'begin', 'year', '...', 'happy', 'new', 'year', '😁❤️😁', 'deepika', 'padukone', 'deepikapfc', 'haha', 'deepikapadukone', 'gon', 'love', 'https', '//twitter.com/sailee_rk/status/1079964902268141568', 'ranveer', 'deepika', 'present', 'honeymoon', 'tying', 'knot', 'november', 'last', 'year', 'italy', 'lake', 'como'], ['couple', 'went', 'host', 'three', 'wedding', 'receptions', 'mumbai', 'bengaluru'], ['ranveer', 'occupied', 'promotion', 'film', 'simmba', 'already', 'made', '100', 'crore', 'box', 'office'], ['interview', 'actor', 'said', 'relationship', 'deepika', 'seeing', 'six', 'years'], ['period', 'time', 'grown', 'evolved', 'together'], ['deepika', 'person', 'used', 'six', 'years', 'back', 'neither'], ['growth', 'evolution', 'happened', 'stayed', 'connected'], ['evolution', 'human', 'beings', 'happened', 'together'], ['really', 'stronger', 'ever', 'before.', 'ranveer', 'singh', 'phenomenal', '2018'], ['terms', 'box', 'office', 'revenue', 'biggest', 'star', 'year', 'two', 'films', 'made', '400', 'crore', 'box', 'office', 'number', 'set', 'high', 'simmba', 'still', 'wreaking', 'havoc', 'box', 'office'], ['upcoming', 'february', 'release', 'gully', 'boy', 'selected', 'berlin', 'film', 'festival'], ['turned', 'new', 'leaf', 'life', 'married', 'india', 'top', 'superstar', 'deepika', 'padukone'], ['talking', 'much', 'talked', 'marriage', 'deepika', 'padukone', 'ranveer', 'added', 'despite', 'biggest', 'blockbuster', 'padmaavat', 'herogiri', 'simmba', 'appreciated', 'one', 'believes', 'marriage', 'deepika', 'padukone', 'life', 'biggest', 'achievement'], ['also', 'added', 'feels', 'superpower', 'feels', 'invincible', 'protected', 'knowing', 'deepika', 'side', 'cares'], ['deepika', 'padukone', 'reveals', 'relationship', 'ranveer', 'singh', 'evolved', 'years', 'deepika', 'padukone', 'ranveer', 'singh', 'currently', 'one', 'talked', 'couples', 'bollywood'], ['duo', 'lately', 'dodging', 'questions', 'related', 'marriage.in', 'recent', 'interview', 'femina', 'magazine', 'actress', 'asked', 'relationship', 'ranveer', 'singh', 'evolved', 'years', 'reportedly', 'replied', 'connect', 'people', 'lives', 'relationship', 'bound', 'evolve', 'ranveer', 'feel', 'connection'], ['said', 'feels', 'great', 'find', 'ranveer', 'someone', 'depended', 'upon', 'trusted', 'someone', 'puts', 'others'], ['adding', 'said', 'fun', 'honest'], ['considers', 'best', 'friend.meanwhile', 'work', 'front', 'actress', 'set', 'work', 'alongside', 'meghna', 'gulzar', 'untitled', 'next', 'ranveer', 'working', \"'simmba\", \"'gully\", 'boy', 'karan', 'johar', 'magnum', 'opus', \"'takht\"], ['ranveer', 'singh', 'said', 'working', 'towards', 'becoming', 'husband', 'millennium', 'joking'], ['letting', 'deepika', 'padukone', 'take', 'reins', 'intimate', 'wedding', 'italy', 'celebrations', 'followed', 'hunk', 'earning', 'major', 'husband', 'points', 'putting', 'wife', 'first', 'ways'], ['following', 'advice', 'say', 'yes', 'everything', 'says', 'star', 'recently', 'opened', 'embracing', 'fatherhood', 'near', 'future'], ['speaking', 'news', 'portal', 'spilled', 'beans', 'starting', 'family', 'superstar', 'wife', 'reportedly', 'said', 'partly', 'call', 'mostly', 'deepika', 'decision', 'respect'], ['meanwhile', 'deepika', 'recently', 'spoke', 'couple', 'honeymoon', 'plans', 'revealed', 'planned', 'anything', 'yet', 'currently', 'busy', 'ranveer', 'simmba', 'promotions'], ['one', 'spoken', 'weddings', 'last', 'year', 'ranve', 'deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'become', 'one', 'most-talked-about', 'bollywood', 'parties', '2018'], [], ['every', 'day', 'two', 'film', 'industry', 'biggest', 'stars', 'tie', 'knot', 'together', 'picturesque', 'location', 'lake', 'como'], ['ranveer', 'deepika', 'decided', 'take', 'relationship', 'next', 'level', 'six', 'years', 'dating', 'fans', 'friends', 'ecstatic'], ['though', 'ranveer', 'earlier', 'revealed', 'within', 'six', 'months', 'dating', 'knew', 'deepika', 'one', 'piku', 'actress', 'took', 'sweet', 'time', 'say', 'yes', 'marriage'], ['recently', 'deepika', 'interview', 'magazine', 'revealed', 'first', 'time', 'thought', 'marrying', 'ranveer'], ['thought', 'marrying', 'ranveer', 'padmaavat'], ['knew', 'going', 'happen', 'matter', 'time'], ['film', 'released', 'felt', 'correct'], ['course', 'ready', 'already', 'committed', 'projects'], [\"n't\", 'sure', 'able', 'take', 'time'], ['made', 'work', 'said', 'deepika'], ['deepika', 'ranveer', 'tied', 'knot', 'lake', 'como', 'italy', 'november', 'presence', 'family', 'close', 'friends'], ['two', 'weddings', 'five', 'receptions', 'later', 'newlyweds', 'finally', 'taken', 'honeymoon'], ['eepika', 'padukone', 'ranveer', 'singh', 'made', 'fans', 'hearts', 'melt', 'happiness', 'tied', 'knot', 'november', 'six', 'years', 'dating'], ['romance', 'bloomed', 'sets', 'goliyon', 'rasleela', 'ram', 'leela', 'grew', 'stronger', 'day'], ['longest', 'time', 'two', 'preferred', 'dodge', 'questions', 'relationship'], ['however', 'public', 'appearances', 'hand-holding', 'public', 'confirmed', 'speculation', 'true'], ['beginning', '2018', 'much', 'talk', 'engagement', 'supposed', 'happened', 'sri', 'lanka'], ['marriage', 'details', 'first', 'meeting', 'dates', 'trickling'], ['deepika', 'revealed', 'entertainment', 'portal', 'gotten', 'engaged', 'four', 'years', 'ago'], ['asked', 'thought', 'ranveer', 'special', 'said', 'yash', 'raj', 'flirting', 'like', 'nobody', 'business', 'dating', 'somebody', 'else', 'point', 'smiling', 'told', 'flirting', 'me.', 'deepika', 'also', 'revealed', 'used', 'frequent', 'restaurants', 'dating', 'special', 'moments', 'ram', 'leela', 'director', 'sanjay', 'leela', 'bhansali', 'house'], ['sir', 'called', 'lunch', 'eating', 'apparently', 'piece', 'crab', 'stuck', 'tooth', 'wanted', 'make', 'awkward', 'said', 'crab', 'stuck', 'mouth', 'said', 'take'], ['moment', 'three', 'forget', 'said'], ['ranveer', 'deepika', 'open', 'social-media', 'pda'], ['recently', 'deepika', 'announced', 'title', 'new', 'film', 'chhapaak', 'plays', 'acid', 'attack', 'survivor', 'laxmi', 'aggarwal', 'ranveer', 'praise'], ['commented', 'photo', 'saying', 'proud', 'baby'], ['ranveer', 'deepika', 'got', 'married', 'two', 'days', 'picturesque', 'villa', 'del', 'balbianello', 'italy'], ['traditional', 'konkani-style', 'nuptials', 'november', 'followed', 'anand', 'karaj', 'ceremony', 'november'], ['ranveer', 'deepika', 'hosted', 'three', 'receptions', 'one', 'actress', 'hometown', 'bengaluru', 'followed', 'two', 'parties', 'mumbai'], ['soon', 'wedding', 'festivities', 'came', 'end', 'ranveer', 'threw', 'promotions', 'rohit', 'shetty', 'simmba'], ['recent', 'interview', 'ranveer', 'opened', 'deepika', 'decided', 'one'], ['six', 'months', 'relationship', 'knew', 'one'], ['nurtured', 'relationship', 'accordingly'], ['six', 'years'], ['good', 'lovely'], ['force', 'nature'], ['understood', 'almost', 'immediately.'], ['added', 'lucky'], ['knew', 'well', 'woman', 'going', 'marry'], ['woman', 'would', 'become', 'mother', 'children'], ['thinking', 'marriage', 'seriously', 'almost', 'three', 'years'], ['waiting', 'told', 'minute', 'say'], ['b-town', 'excited', 'fairytale', 'wedding', 'ranveer', 'singh', 'deepika', 'padukone', 'ever', 'since', 'couple', 'announced', 'wedding', 'dates'], ['know', 'started', 'met', 'got', 'know', 'sets', 'first', 'film', 'sanjay', 'leela', 'bhansali', 'goliyon', 'rasleela', 'ram-leela', 'gulshan', 'devaiah', 'also', 'part', 'film', 'opened', 'recently', 'started', 'blossomed'], ['talking', 'love-story', 'reportedly', 'said', 'romance', 'started', 'sets', 'goliyon', 'rasleela', 'ram-leela', 'saw', 'getting', 'close', 'first', 'day', 'shoot'], ['also', 'said', 'still', 'remembers', 'udaipur', 'schedule', 'saw', 'deepika', 'sitting', 'ranveer', 'lap', 'surprised', 'quite', 'bit'], ['said', 'romance', 'come', 'long', 'way'], ['romance', 'fondest', 'memory', 'right', 'saw', 'himself.meanwhile', 'deepika', 'padukone', 'ranveer', 'singh', 'tie', 'knot', '14th', '15th', 'november', 'year'], ['ranveer', 'singh', 'one', 'loving', 'boyfriend', 'deepika', 'padukone', 'never', 'thought', 'twice', 'displaying', 'affection', 'husband', 'even', 'doting', 'supportive'], ['latest', 'comment', 'deepika', 'padukone', 'next', 'film', 'announcement', 'instagram', 'proof'], ['taking', 'social', 'media', 'handles', 'deepika', 'announced', 'upcoming', 'film', 'chhapaak', 'picture', 'quotation', 'read', 'story', 'trauma', 'triumph', 'unquashable', 'human', 'spirit'], ['lauding', 'choice', 'film', 'ranveer', 'took', 'comments', 'section', 'wrote', 'proud', 'baby']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-JDRx1S9arQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lib\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2k6ddD39arT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(text, size= 100, window= 10, min_count= 2)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2TiwGwo9arV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "901835a8-cea6-476f-9332-e306e6ce1076"
      },
      "source": [
        "word = model.wv.vocab\n",
        "word.keys()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018', 'celebrations', 'waiting', 'come', 'also', 'gave', 'two', 'couple', 'airport', 'looks', 'reception', 'parties', 'everything', 'style', 'priyanka', 'nick', 'man', 'year', 'big', 'lavish', 'weddings', 'isha', 'ambani', 'anand', 'piramal', 'chopra', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', 'saw', 'many', 'grand', 'social', 'media', 'flew', 'lake', 'como', 'tie', 'knot', 'days', 'november', 'several', 'bengaluru', 'mumbai', 'even', 'tied', 'american', 'singer', 'jodhpur', 'december', 'yet', 'another', 'week', 'hosted', 'delhi', 'host', 'party', 'los', 'angeles', 'time', 'could', 'pre-wedding', 'festivities', 'took', 'udaipur', 'pop', 'soon', 'event', 'followed', 'three', 'stars', 'star', 'married', 'player', 'cricketer', 'much', 'like', 'couples', 'cake', 'appearances', 'see', 'white', 'italy', 'ceremonies', 'sindhi', 'seen', 'wearing', 'custom-made', 'sabyasachi', 'traditional', 'gorgeous', 'silk', 'saree', 'perfect', 'made', 'way', 'back', 'love', 'wore', 'added', 'began', 'bangalore', 'stunning', 'sherwani', 'long', 'right', 'fairytale', 'receptions', 'umaid', 'bhawan', 'palace', 'since', \"n't\", 'pictures', 'thought', 'got', 'felt', 'beautiful', 'looking', 'extremely', 'moment', 'make', 'four', 'topped', 'still', 'newlyweds', 'reportedly', 'friends', 'reports', 'close', 'among', 'films', 'meanwhile', 'industry', 'less', 'dating', 'months', 'duo', 'decided', 'take', 'relationship', 'next', 'level', 'instagram', 'story', 'posting', 'best', 'moments', 'diva', 'place', 'adorable', 'would', 'announced', 'giving', 'major', 'goals', 'christian', 'bar', 'picture', 'wherein', 'ago', 'peecee', 'taken', 'share', 'posing', 'wife', 'become', 'loved', 'always', 'look', 'together', 'latest', 'proof', 'light', 'give', 'bhavan', 'presence', 'threw', 'recently', 'post', 'photo', 'shoot', 'captioned', 'filled', 'fans', 'followers', 'actress', 'shared', 'nieces', 'actor', 'handle', 'working', 'keys', 'teaching', 'know', 'open', 'starting', 'family', 'speaking', 'said', 'called', 'tying', 'set', 'virat', 'kohli', 'anushka', 'new', 'sydney', 'australia', 'photos', 'ready', 'husband', 'busy', 'test', 'india', 'series', 'kapoor', 'others', 'b-town', 'alia', 'ranbir', 'riddhima', 'happy', '2019', 'cancer', 'zodiac', 'sign', 'hope', 'future', 'happiness', 'good', 'wrote', 'within', 'news', 'dosa', 'saying', 'great', 'begin', '...', 'deepikapadukone', 'honeymoon', 'last', 'film', 'simmba', 'already', 'crore', 'box', 'office', 'interview', 'six', 'years', 'evolved', 'used', 'evolution', 'human', 'stronger', 'ever', 'upcoming', 'boy', 'life', 'superstar', 'talking', 'talked', 'marriage', 'padmaavat', 'feels', 'currently', 'questions', 'recent', 'magazine', 'asked', 'someone', 'work', 'first', 'say', 'yes', 'opened', 'portal', 'revealed', 'promotions', 'day', 'picturesque', 'knew', 'marrying', 'going', 'romance', 'sets', 'goliyon', 'rasleela', 'ram', 'leela', 'public', 'dates', 'special', 'flirting', 'told', 'sanjay', 'bhansali', 'crab', 'stuck', 'chhapaak', 'proud', 'baby', 'almost', 'woman', 'started', 'ram-leela'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knSqt9OF9arX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "56f7eac9-8ae0-4a44-a2c8-144c7b7d7188"
      },
      "source": [
        "model['nick']"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.8621913e-03, -2.0515082e-04,  6.3858822e-04, -8.6055323e-04,\n",
              "       -2.4759721e-03,  1.1712040e-03,  2.2154090e-03,  2.0525013e-05,\n",
              "       -4.0697204e-03, -5.0858120e-03,  2.5217290e-04,  7.8432204e-04,\n",
              "        3.5915752e-03, -2.1355663e-04, -3.8461166e-03,  3.4058844e-03,\n",
              "       -5.5755512e-04,  4.9911360e-03, -1.3874776e-03, -1.0732628e-03,\n",
              "        1.7077090e-04,  1.8757195e-03, -2.3901912e-03, -3.0386650e-03,\n",
              "        2.8603077e-03,  1.3546457e-03,  9.4087806e-04,  1.1219215e-03,\n",
              "       -1.7312845e-03,  4.0384373e-03, -4.1738208e-03, -4.1057235e-03,\n",
              "       -2.8084610e-03, -1.1593305e-03, -1.2666425e-04, -2.4157108e-03,\n",
              "        1.4175175e-03, -4.9279369e-03,  5.0097327e-03, -4.4084559e-03,\n",
              "       -4.7290404e-03, -4.9083070e-03,  4.0698764e-03,  4.7234125e-03,\n",
              "        4.6677832e-03, -4.5823785e-03, -2.4699089e-03,  2.5960170e-03,\n",
              "        1.7973717e-04,  1.5634418e-03,  3.8455368e-03, -2.2028040e-03,\n",
              "       -7.2895311e-04, -4.1146525e-03, -2.1693269e-03, -2.3004945e-04,\n",
              "        2.1202124e-03, -4.7962452e-04, -1.5131237e-03, -3.4914194e-03,\n",
              "        2.3903984e-03,  2.7644162e-03,  2.4473278e-03,  4.0230155e-03,\n",
              "       -1.2120933e-03,  5.2967796e-04,  2.3772949e-03,  1.9503937e-03,\n",
              "        1.3844218e-03,  2.4765988e-03, -4.2266035e-03,  3.9765313e-03,\n",
              "       -8.0951472e-04,  7.3406263e-04, -3.2291957e-03,  2.2382843e-03,\n",
              "       -8.3722873e-04, -3.8357403e-03,  2.4842835e-04, -4.5884928e-05,\n",
              "        4.2963172e-03,  2.9453582e-03,  2.2248277e-03,  6.1646494e-04,\n",
              "       -1.7871428e-03, -2.6509098e-03, -4.4424208e-03,  3.5752261e-03,\n",
              "        4.6739497e-04, -4.7805551e-03, -3.9084409e-03,  9.2725951e-04,\n",
              "       -3.7256957e-03,  1.4484960e-03, -1.7148620e-03,  7.6702191e-04,\n",
              "       -1.5499336e-03, -7.8933750e-04, -2.0093755e-03, -1.1147994e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh8rAD2D9arZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "73b8a8f0-5e14-4ece-90a9-68b6f13af735"
      },
      "source": [
        "model['nick'].shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69sy-cdm9arr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_actor(a, b, c, model):\n",
        "    \"\"\"Accepts a triad of words, a,b,c and returns d such that a is to b : c is to d\"\"\"\n",
        "    actors = [\"ranveer\",\"deepika\",\"padukone\",\"singh\",\"nick\",\"jonas\",\"chopra\",\"priyanka\",\"virat\",\"anushka\"]\n",
        "\n",
        "    wv_a, wv_b, wv_c = model[a], model[b], model[c]\n",
        "    min_sim = -10\n",
        "    pred = None\n",
        "\n",
        "    for w in actors:\n",
        "        if w == a or w == b or w == c:\n",
        "            continue\n",
        "        \n",
        "        wv_w = model[w]\n",
        "\n",
        "        temp_sim = cosine_similarity([wv_b - wv_a], [wv_w - wv_c])\n",
        "\n",
        "        if temp_sim > min_sim:\n",
        "            min_sim = temp_sim\n",
        "            pred = w\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKuRaLJz9art",
        "colab_type": "text"
      },
      "source": [
        "### 4. Test your Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBbupnFVmEAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvWffD4G9art",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "4d2a0aae-7b0d-4f9f-9670-959a02c3d1c7"
      },
      "source": [
        "a, b, c = \"nick\", \"priyanka\", \"virat\"\n",
        "print(predict_actor(a, b, c, model))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chopra\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdnqnwwa9arv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "478c435e-d5f6-4707-e9ca-b6cdfa78ec32"
      },
      "source": [
        "a, b, c = \"ranveer\", \"deepika\", \"priyanka\"\n",
        "print(predict_actor(a, b, c, model))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anushka\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvY2DY8d9arx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e3307b5f-aeea-4a58-d7b7-e0920c00f515"
      },
      "source": [
        "a,b,c = \"ranveer\", \"singh\", \"deepika\"\n",
        "predict_actor(a, b, c, model)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'priyanka'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGC58p6f9ar2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "068164a0-66e2-412f-ff04-fbdbabd70b95"
      },
      "source": [
        "triad = (\"deepika\",\"padukone\",\"priyanka\")\n",
        "predict_actor(*triad, model)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'jonas'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP2M7qDw9ar4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "70ba516c-cc35-46b4-ee72-e0417fb9f4cf"
      },
      "source": [
        "triad = (\"priyanka\",\"jonas\",\"nick\")\n",
        "predict_actor(*triad, model)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'virat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVeIkxqTojA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}